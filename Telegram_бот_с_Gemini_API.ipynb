{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladimirBurianitsa/VladimirBurianitsa/blob/main/Telegram_%D0%B1%D0%BE%D1%82_%D1%81_Gemini_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-telegram-bot==13.15\n",
        "%pip install google-generativeai"
      ],
      "metadata": {
        "id": "VRmgnsgebtyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show python-telegram-bot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff6v9uP19JPj",
        "outputId": "9a26efcb-abe1-49cb-e8eb-8d2f768efc88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: python-telegram-bot\n",
            "Version: 13.15\n",
            "Summary: We have made you a wrapper you can't refuse\n",
            "Home-page: https://python-telegram-bot.org/\n",
            "Author: Leandro Toledo\n",
            "Author-email: devs@python-telegram-bot.org\n",
            "License: LGPLv3\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: APScheduler, cachetools, certifi, pytz, tornado\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# Импортируем необходимые библиотеки\n",
        "import telegram\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
        "import google.generativeai as genai\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Настройка логирования для отслеживания событий и ошибок\n",
        "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- НАСТРОЙКИ ---\n",
        "# Замените 'YOUR_TELEGRAM_BOT_TOKEN' на ваш токен Telegram бота\n",
        "TELEGRAM_BOT_TOKEN = '8080874256:AAH4iWRF_7t89yiYhpmfgreNY8wmsNqJE'\n",
        "# Замените 'YOUR_GEMINI_API_KEY' на ваш ключ API Gemini\n",
        "GEMINI_API_KEY = 'AIzaSyClWrkvawYE3eXKZWOHBSiQy8wK6DA2nM8'\n",
        "\n",
        "# Проверка наличия API ключей (лучше использовать переменные окружения)\n",
        "if TELEGRAM_BOT_TOKEN == 'YOUR_TELEGRAM_BOT_TOKEN' or GEMINI_API_KEY == 'YOUR_GEMINI_API_KEY':\n",
        "    logger.warning(\"Пожалуйста, замените 'YOUR_TELEGRAM_BOT_TOKEN' и 'YOUR_GEMINI_API_KEY' на ваши реальные ключи.\")\n",
        "    # Для демонстрации можно использовать переменные окружения, если они заданы\n",
        "    TELEGRAM_BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN', TELEGRAM_BOT_TOKEN)\n",
        "    GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', GEMINI_API_KEY)\n",
        "\n",
        "# Настройка Gemini API\n",
        "try:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    # Выбор модели Gemini. 'gemini-pro' хорошо подходит для текстовых задач.\n",
        "    # Для более сложных задач или мультимодальных возможностей можно использовать 'gemini-1.5-pro-latest' или 'gemini-pro-vision'\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    logger.info(\"Gemini API успешно настроен.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Ошибка при настройке Gemini API: {e}\")\n",
        "    model = None # Устанавливаем модель в None, если настройка не удалась\n",
        "\n",
        "# --- ФУНКЦИИ-ОБРАБОТЧИКИ TELEGRAM ---\n",
        "\n",
        "def start(update, context):\n",
        "    \"\"\"Отправляет приветственное сообщение при команде /start.\"\"\"\n",
        "    user = update.effective_user\n",
        "    welcome_message = (\n",
        "        f\"Привет, {user.first_name}!\\n\\n\"\n",
        "        \"Я чат-бот, использующий Gemini API для генерации ответов. \"\n",
        "        \"Просто напиши мне что-нибудь, и я постараюсь ответить.\"\n",
        "    )\n",
        "    update.message.reply_html(welcome_message)\n",
        "    logger.info(f\"Пользователь {user.id} ({user.username}) запустил бота.\")\n",
        "\n",
        "def handle_message(update, context):\n",
        "    \"\"\"Обрабатывает текстовые сообщения пользователя и отвечает с помощью Gemini.\"\"\"\n",
        "    user_message = update.message.text\n",
        "    user = update.effective_user\n",
        "    chat_id = update.message.chat_id\n",
        "\n",
        "    logger.info(f\"Получено сообщение от {user.id} ({user.username}): '{user_message}'\")\n",
        "\n",
        "    if not model:\n",
        "        update.message.reply_text(\"Извините, произошла ошибка при подключении к Gemini API. Попробуйте позже.\")\n",
        "        logger.error(\"Модель Gemini не инициализирована. Невозможно обработать сообщение.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Отправляем индикатор \"печатает...\"\n",
        "        context.bot.send_chat_action(chat_id=chat_id, action=telegram.ChatAction.TYPING)\n",
        "\n",
        "        # Генерация ответа с помощью Gemini API\n",
        "        # Для более сложных диалогов можно передавать историю сообщений\n",
        "        # response = model.generate_content(user_message, stream=True) # stream=True для потоковой передачи\n",
        "        response = model.generate_content(user_message)\n",
        "\n",
        "        # Извлечение текста из ответа Gemini\n",
        "        # Обратите внимание, что структура ответа может немного отличаться в зависимости от модели и настроек\n",
        "        if response and response.text:\n",
        "            bot_response = response.text\n",
        "        else:\n",
        "            # Попытка получить текст из частей, если .text пуст (например, для некоторых потоковых ответов или моделей)\n",
        "            bot_response_parts = []\n",
        "            if response and hasattr(response, 'parts'):\n",
        "                 for part in response.parts:\n",
        "                    if hasattr(part, 'text'):\n",
        "                        bot_response_parts.append(part.text)\n",
        "            if bot_response_parts:\n",
        "                bot_response = \"\".join(bot_response_parts)\n",
        "            else:\n",
        "                bot_response = \"Извините, я не смог сгенерировать ответ. Попробуйте переформулировать ваш запрос.\"\n",
        "                logger.warning(f\"Gemini API вернул пустой или неожиданный ответ на запрос: '{user_message}'. Ответ: {response}\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Ответ от Gemini: '{bot_response[:100]}...'\") # Логируем только начало длинного ответа\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка при обращении к Gemini API: {e}\")\n",
        "        bot_response = \"Произошла ошибка при обработке вашего запроса. Пожалуйста, попробуйте еще раз позже.\"\n",
        "\n",
        "    # Отправка ответа пользователю\n",
        "    update.message.reply_text(bot_response)\n",
        "\n",
        "def error_handler(update, context):\n",
        "    \"\"\"Логирует ошибки, вызванные обновлениями.\"\"\"\n",
        "    logger.warning(f'Update \"{update}\" caused error \"{context.error}\"')\n",
        "\n",
        "# --- ОСНОВНАЯ ЧАСТЬ БОТА ---\n",
        "\n",
        "def main():\n",
        "    \"\"\"Запускает бота.\"\"\"\n",
        "    if TELEGRAM_BOT_TOKEN == 'YOUR_TELEGRAM_BOT_TOKEN' or not TELEGRAM_BOT_TOKEN:\n",
        "        logger.error(\"Токен Telegram бота не найден. Пожалуйста, установите TELEGRAM_BOT_TOKEN.\")\n",
        "        return\n",
        "\n",
        "    if GEMINI_API_KEY == 'YOUR_GEMINI_API_KEY' or not GEMINI_API_KEY or not model:\n",
        "        logger.error(\"Ключ Gemini API не найден или модель не инициализирована. Бот не может использовать Gemini.\")\n",
        "        # Можно запустить бота без Gemini, но он не будет отвечать на сообщения осмысленно\n",
        "        # или просто завершить работу, как здесь.\n",
        "        return\n",
        "\n",
        "    # Создание Updater и передача ему токена вашего бота.\n",
        "    updater = Updater(TELEGRAM_BOT_TOKEN, use_context=True)\n",
        "\n",
        "    # Получение диспетчера для регистрации обработчиков\n",
        "    dp = updater.dispatcher\n",
        "\n",
        "    # Регистрация обработчиков команд\n",
        "    dp.add_handler(CommandHandler(\"start\", start))\n",
        "    # dp.add_handler(CommandHandler(\"help\", help_command)) # Можете добавить команду помощи\n",
        "\n",
        "    # Регистрация обработчика текстовых сообщений\n",
        "    # Filters.text & (~Filters.command) означает, что обрабатываются только текстовые сообщения, не являющиеся командами\n",
        "    dp.add_handler(MessageHandler(Filters.text & (~Filters.command), handle_message))\n",
        "\n",
        "    # Регистрация обработчика ошибок\n",
        "    dp.add_error_handler(error_handler)\n",
        "\n",
        "    # Запуск бота\n",
        "    updater.start_polling()\n",
        "    logger.info(\"Телеграм-бот запущен и ожидает сообщений...\")\n",
        "\n",
        "    # Бот будет работать до тех пор, пока вы не нажмете Ctrl-C\n",
        "    updater.idle()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "77C4W4Ukac7h"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}